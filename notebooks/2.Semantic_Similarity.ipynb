{
    "cells": [
     {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4c372709-bac5-4234-b6a1-05ede45b1b01",
      "metadata": {},
      "outputs": [],
      "source": [
       "from sentence_transformers import SentenceTransformer\n",
       "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
       "from typing import List, Any\n",
       "import numpy as np\n",
       "\n",
       "class EmbeddingModel():\n",
       "    \"\"\"\n",
       "        An embedding model class\n",
       "    \"\"\"\n",
       "    def __init__(self, model_checkpoint:str, type:str=\"hf\", openai_token:str=\"\", cohere_token:str=\"\", device:str=\"\"):\n",
       "        self.model_checkpoint = model_checkpoint\n",
       "        self.type = type\n",
       "\n",
       "        if type == \"openai\":\n",
       "            self.model = OpenAI(api_key=openai_token)\n",
       "        elif type == \"cohere\":\n",
       "            self.model = cohere.Client(cohere_token)\n",
       "        elif type == \"hf\": # huggingface\n",
       "            self.model = SentenceTransformer(model_checkpoint).to(device)\n",
       "        else:\n",
       "            raise ValueError(f\"We only support openai, cohere, and hf as model_checkpoint type.\")\n",
       "    \n",
       "    def get_openai_embedding(self, texts):\n",
       "        data = self.model.embeddings.create(input = texts, model=self.model_checkpoint).data\n",
       "        embeddings = []\n",
       "        for obj in data:\n",
       "            embeddings.append(obj.embedding)\n",
       "        return embeddings\n",
       "\n",
       "    def get_cohere_embedding(self, texts):\n",
       "        response = self.model.embed(texts=texts, model=self.model_checkpoint, input_type=\"search_query\")\n",
       "        return response.embeddings\n",
       "\n",
       "    def encode(self, texts):\n",
       "        if self.type == \"openai\":\n",
       "            embeddings = self.get_openai_embedding(texts)\n",
       "        elif self.type == \"cohere\":\n",
       "            embeddings = self.get_cohere_embedding(texts)\n",
       "        else:\n",
       "            embeddings = self.model.encode(texts)\n",
       "        return embeddings\n",
       "\n",
       "\n",
       "class DistFuse():\n",
       "    \"\"\"\n",
       "        A DistFuse class to compute similarity scores from multiple models.\n",
       "    \n",
       "        e.g.,\n",
       "            from distfuse import DistFuse\n",
       "\n",
       "            model_checkpoints = [[\"sentence-transformers/LaBSE\", \"hf\"], [\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", \"hf\"]]\n",
       "            weights = [1, 1]\n",
       "            dist_measure = \"cosine\"\n",
       "            model = DistFuse(model_checkpoints, weights, dist_measure=dist_measure)\n",
       "            \n",
       "            scores = model.score_pair([\"I like apple\", \"I like cats\"], [\"I like orange\", \"I like dogs\"])\n",
       "            print(scores)\n",
       "    \"\"\"\n",
       "    def __init__(self, model_checkpoints:List[List[str]], weights:List[float]=None, instructions:List[str]=None, dist_measure:str=\"euclid\", openai_token:str=None, cohere_token:str=None, device:str=None):\n",
       "        \"\"\"\n",
       "            Args:\n",
       "                model_checkpoints (List[str]): a list of model checkpoints and types\n",
       "                weights (List[float]): a list of weights\n",
       "                instructions (List[str]): a list of instructions\n",
       "                dist_measure (str): the distance measure (only accept euclidean, cosine, manhattan, by default: euclidean)\n",
       "                openai_token (str): openai token\n",
       "                cohere_token (str): cohere token\n",
       "                device (str): device\n",
       "        \"\"\"\n",
       "        self.model_checkpoints = model_checkpoints\n",
       "        self.models = []\n",
       "        self.instructions = []\n",
       "        self.opt = None\n",
       "\n",
       "        if dist_measure == \"euclidean\":\n",
       "            self.dist_measure = euclidean_distances\n",
       "            self.opt = np.min\n",
       "        elif dist_measure == \"cosine\":\n",
       "            self.dist_measure = cosine_similarity\n",
       "            self.opt = np.max\n",
       "        elif dist_measure == \"manhattan\":\n",
       "            self.dist_measure = manhattan_distances\n",
       "            self.opt = np.min\n",
       "        else:\n",
       "            raise ValueError(f\"dist_measure {dist_measure} is not found.\")\n",
       "\n",
       "        for i in range(len(self.model_checkpoints)):\n",
       "            model_checkpoint = self.model_checkpoints[i]\n",
       "            model = EmbeddingModel(model_checkpoint[0], type=model_checkpoint[1], openai_token=openai_token, cohere_token=cohere_token, device=device)\n",
       "            self.models.append(model)\n",
       "\n",
       "            if instructions is None:\n",
       "                self.instructions.append(\"\")\n",
       "            else:\n",
       "                assert len(instructions) == len(self.model_checkpoints)\n",
       "                self.instructions.append(instructions[i])\n",
       "\n",
       "        if weights is None:\n",
       "            self.weights = [1] * len(self.models)\n",
       "        else:\n",
       "            self.weights = weights\n",
       "\n",
       "        assert len(self.models) == len(self.weights)\n",
       "\n",
       "    def get_detailed_instruct(self, task_description: str, query: str) -> str:\n",
       "        return f'Instruct: {task_description}\\nQuery: {query}'\n",
       "\n",
       "    def score_references(self, predictions:List[str], references:List[List[str]]) -> List[float]:\n",
       "        \"\"\"\n",
       "            Compute the scores of predictions and references. Each prediction can have a multiple references.\n",
       "            Args:\n",
       "                predictions (List[str]): a list of text sequences (m samples)\n",
       "                references (List[List[str]]): a list of list with text sequences (m x r samples) where r is the number of references\n",
       "            Returns:\n",
       "                List[float]: a list of scores (m dimensions)\n",
       "        \"\"\"\n",
       "        assert len(predictions) > 0 and len(references) > 0\n",
       "        assert len(predictions) == len(references)\n",
       "\n",
       "        scores = []\n",
       "        for model_id, model in zip(range(len(self.models)), self.models):\n",
       "            instruction = self.instructions[model_id]\n",
       "            if instruction != \"\":\n",
       "                instruction_predictions = []\n",
       "                instruction_references = []\n",
       "                for prediction, reference in zip(predictions, references):\n",
       "                    instruction_predictions.append(self.get_detailed_instruct(instruction, prediction))\n",
       "                    instruction_references.append(self.get_detailed_instruct(instruction, reference))\n",
       "                embs1 = model.encode(instruction_predictions)\n",
       "                embs2 = model.encode(instruction_references)\n",
       "            else:\n",
       "                embs1 = model.encode(predictions)\n",
       "                embs2 = model.encode(references)\n",
       "        \n",
       "            scores_per_model = []\n",
       "            for i in range(len(embs1)):\n",
       "                reference_scores = self.dist_measure([embs1[i]], [embs2[i]])\n",
       "                reference_scores = self.opt(np.array(reference_scores), axis=-1).tolist()[0]\n",
       "                scores_per_model.append(reference_scores)\n",
       "            scores.append(scores_per_model)\n",
       "\n",
       "        final_scores = scores[0]\n",
       "        for model_id in range(1, len(scores)):\n",
       "            for j in range(len(final_scores)):\n",
       "                final_scores[j] += scores[model_id][j] * self.weights[model_id]\n",
       "        return final_scores\n",
       "\n",
       "\n",
       "    def score_pairs(self, text_list1:List[str], text_list2:List[str]) -> List[float]:\n",
       "        \"\"\"\n",
       "            Compute the scores of two text sequence lists\n",
       "            Args:\n",
       "                text_list1 (List[str]): a list of text sequences (m samples)\n",
       "                text_list2 (List[str]): a list of text sequences (n samples)\n",
       "            Returns:\n",
       "                List[float]: a list of scores (m x n dimensions)\n",
       "        \"\"\"\n",
       "        \n",
       "        assert len(text_list1) > 0 and len(text_list2) > 0\n",
       "\n",
       "        scores = []\n",
       "        for model_id, model in zip(range(len(self.models)), self.models):\n",
       "            instruction = self.instructions[model_id]\n",
       "            if instruction != \"\":\n",
       "                instruction_predictions = []\n",
       "                instruction_references = []\n",
       "                for prediction, reference in zip(text_list1, text_list2):\n",
       "                    instruction_predictions.append(self.get_detailed_instruct(instruction, prediction))\n",
       "                    instruction_references.append(self.get_detailed_instruct(instruction, reference))\n",
       "                embs1 = model.encode(instruction_predictions)\n",
       "                embs2 = model.encode(instruction_references)\n",
       "            else:\n",
       "                embs1 = model.encode(text_list1)\n",
       "                embs2 = model.encode(text_list2)\n",
       "\n",
       "            scores.append(self.dist_measure(embs1, embs2))\n",
       "\n",
       "        final_scores = scores[0]\n",
       "        for model_id in range(1, len(scores)):\n",
       "            final_scores = final_scores + scores[model_id] * self.weights[model_id]\n",
       "        return final_scores"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4804242d-d9ce-47f5-a12c-cc493ba2d486",
      "metadata": {},
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "6e5c8002747d4966b75b8a9b7931022a",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "aa0950031aec45e19aba30db7fe15701",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "config_sentence_transformers.json:   0%|          | 0.00/128 [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "3849b39456df45eea01cd03ffad6b58b",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "README.md:   0%|          | 0.00/140k [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "a477b43033d3465bbda317c690b7df3b",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "6a58330201de4a1ab121ddbb37d383aa",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "81652ff0b4c84a9fa8ae886bfdc5c7b1",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "tokenizer_config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "f7ea8422aab34046a8ae3ea086d733b3",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "9bf986a7593f4e50a48fa340c18e75ac",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "e20f048abf494194b48357ff4035646b",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "500d918ae9f34b45bd92508242cbbe21",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "1_Pooling/config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "model_checkpoints = [[\"intfloat/multilingual-e5-large-instruct\", \"hf\"]]\n",
       "weights = [1]\n",
       "dist_measure = \"cosine\" # cosine, euclidean, manhattan\n",
       "instructions = [\"Retrieve relevant food name and description\"]\n",
       "model = DistFuse(model_checkpoints, weights, instructions, dist_measure=dist_measure, openai_token=\"\", cohere_token=\"\", device=\"cuda:0\")\n",
       "\n",
       "def generate_scores(input, samples):\n",
       "    def create_pairs(input, samples):\n",
       "        pairs.append([[input, sample] for sample in samples])\n",
       "        return pairs\n",
       "\n",
       "    pairs = create_pairs(input, samples)\n",
       "    scores = model.score_pairs(pairs)\n",
       "    print(scores)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 17,
      "id": "78963ff0-6b06-4e69-bd99-ddc324703397",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "[0.8635987639427185, 0.7580072283744812, 0.7714425325393677]\n"
        ]
       }
      ],
      "source": [
       "input = [\"Pizza. The dish consists of a flat base of leavened wheat-based dough topped with tomato, cheese, and other ingredients, baked at a high temperature, traditionally in a wood-fired oven.\"] \n",
       "input = input * 3\n",
       "samples = [\"Pita. The dish is a family of yeast-leavened round flatbreads baked from wheat flour.\"]\n",
       "samples.append(\"Stew peas. The dish is a stew dish prepared using coconut milk, gungo peas (pigeon peas) or red peas (kidney beans), uncured meats and salted meats such as pork and beef as primary ingredients.\")\n",
       "samples.append(\"Dressed herring. A layered salad composed of diced spekesild covered with layers of grated boiled eggs, Vegetable (potatoes, carrots, beetroots), chopped onions, and mayonnaise\")\n",
       "scores = model.score_references(input, samples)\n",
       "\n",
       "print(scores)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "5705e0b0-6071-4392-b15d-614119dec31b",
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   