{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# crawl this folder for only.json files\n",
    "\n",
    "import yaml\n",
    "\n",
    "def load_yaml(file):\n",
    "    with open(file, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "def load_json(file):\n",
    "    with open(file) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "models = load_yaml('../../score.yml')['models']\n",
    "model_map = load_yaml('../../plot/plot_mapper.yml')['model_name_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = \"{model}_accuracy_mc.json\"\n",
    "t2 = \"{model}_accuracy_oe_multi.json\"\n",
    "t3 = \"{model}_bertscore_oe.json\"\n",
    "\n",
    "res = []\n",
    "\n",
    "for model in models:\n",
    "    mc = load_json(t1.format(model=model))\n",
    "    oe = load_json(t2.format(model=model))\n",
    "    bert = load_json(t3.format(model=model))\n",
    "\n",
    "    res.append({\n",
    "        'model': model_map[model],\n",
    "        \n",
    "        '1a mc': mc['1a. Dish Name (No-Context)']['avg_score'],\n",
    "        '1a oe': oe['1a. Dish Name (No-Context)']['avg_score'],\n",
    "\n",
    "        '1b mc': mc['1b. Dish Name (Contextualized)']['avg_score'],\n",
    "        '1b oe': oe['1b. Dish Name (Contextualized)']['avg_score'],\n",
    "        \n",
    "        '1c mc': mc['1c. Dish Name (Adversarial)']['avg_score'],\n",
    "        '1c oe': oe['1c. Dish Name (Adversarial)']['avg_score'],\n",
    "\n",
    "        '2 mc': mc['2. Regional Cuisine']['avg_score'],\n",
    "        '2 oe': oe['2. Regional Cuisine']['avg_score'],\n",
    "\n",
    "        'avg_all_mc': mc['avg_score_all'],\n",
    "        'avg_all_oe': oe['avg_score_all']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>1a mc</th>\n",
       "      <th>1a oe</th>\n",
       "      <th>1b mc</th>\n",
       "      <th>1b oe</th>\n",
       "      <th>1c mc</th>\n",
       "      <th>1c oe</th>\n",
       "      <th>2 mc</th>\n",
       "      <th>2 oe</th>\n",
       "      <th>avg_all_mc</th>\n",
       "      <th>avg_all_oe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemini1.5 Flash</td>\n",
       "      <td>78.17</td>\n",
       "      <td>16.30</td>\n",
       "      <td>82.07</td>\n",
       "      <td>23.53</td>\n",
       "      <td>71.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>66.00</td>\n",
       "      <td>32.30</td>\n",
       "      <td>74.39</td>\n",
       "      <td>19.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT4o</td>\n",
       "      <td>88.40</td>\n",
       "      <td>16.60</td>\n",
       "      <td>90.43</td>\n",
       "      <td>35.47</td>\n",
       "      <td>82.23</td>\n",
       "      <td>12.60</td>\n",
       "      <td>63.60</td>\n",
       "      <td>35.53</td>\n",
       "      <td>81.17</td>\n",
       "      <td>25.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT4o-mini</td>\n",
       "      <td>75.33</td>\n",
       "      <td>7.30</td>\n",
       "      <td>83.00</td>\n",
       "      <td>17.67</td>\n",
       "      <td>64.83</td>\n",
       "      <td>3.53</td>\n",
       "      <td>52.87</td>\n",
       "      <td>26.90</td>\n",
       "      <td>69.01</td>\n",
       "      <td>13.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llava1.6 Vicuna 7B</td>\n",
       "      <td>33.63</td>\n",
       "      <td>0.87</td>\n",
       "      <td>43.13</td>\n",
       "      <td>2.83</td>\n",
       "      <td>28.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>27.77</td>\n",
       "      <td>7.93</td>\n",
       "      <td>33.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llava1.6 Vicuna 13B</td>\n",
       "      <td>40.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>50.30</td>\n",
       "      <td>4.17</td>\n",
       "      <td>38.37</td>\n",
       "      <td>1.60</td>\n",
       "      <td>31.07</td>\n",
       "      <td>8.63</td>\n",
       "      <td>40.15</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Molmo-D 7B</td>\n",
       "      <td>50.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>48.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>36.73</td>\n",
       "      <td>11.70</td>\n",
       "      <td>48.27</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Molmo-O 7B</td>\n",
       "      <td>46.03</td>\n",
       "      <td>2.13</td>\n",
       "      <td>43.27</td>\n",
       "      <td>4.37</td>\n",
       "      <td>41.60</td>\n",
       "      <td>2.10</td>\n",
       "      <td>26.83</td>\n",
       "      <td>9.03</td>\n",
       "      <td>39.43</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Molmo-E 1B</td>\n",
       "      <td>21.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.53</td>\n",
       "      <td>0.13</td>\n",
       "      <td>20.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.60</td>\n",
       "      <td>1.27</td>\n",
       "      <td>21.56</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama 3.2 Instruct 11B</td>\n",
       "      <td>57.93</td>\n",
       "      <td>14.37</td>\n",
       "      <td>65.57</td>\n",
       "      <td>19.20</td>\n",
       "      <td>56.27</td>\n",
       "      <td>9.50</td>\n",
       "      <td>46.60</td>\n",
       "      <td>27.23</td>\n",
       "      <td>56.59</td>\n",
       "      <td>17.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama 3.2 Instruct 90B</td>\n",
       "      <td>77.33</td>\n",
       "      <td>14.27</td>\n",
       "      <td>83.43</td>\n",
       "      <td>22.30</td>\n",
       "      <td>71.23</td>\n",
       "      <td>9.00</td>\n",
       "      <td>64.70</td>\n",
       "      <td>29.73</td>\n",
       "      <td>74.17</td>\n",
       "      <td>18.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pixtral 12B</td>\n",
       "      <td>57.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>72.33</td>\n",
       "      <td>1.83</td>\n",
       "      <td>55.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>44.73</td>\n",
       "      <td>12.83</td>\n",
       "      <td>57.51</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2 VL Instruct 2B</td>\n",
       "      <td>40.97</td>\n",
       "      <td>3.33</td>\n",
       "      <td>44.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>47.07</td>\n",
       "      <td>3.43</td>\n",
       "      <td>48.37</td>\n",
       "      <td>12.50</td>\n",
       "      <td>45.20</td>\n",
       "      <td>5.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2 VL Instruct 7B</td>\n",
       "      <td>63.83</td>\n",
       "      <td>4.07</td>\n",
       "      <td>67.20</td>\n",
       "      <td>8.57</td>\n",
       "      <td>57.00</td>\n",
       "      <td>3.90</td>\n",
       "      <td>56.80</td>\n",
       "      <td>21.23</td>\n",
       "      <td>61.21</td>\n",
       "      <td>9.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aria 25B</td>\n",
       "      <td>65.77</td>\n",
       "      <td>2.67</td>\n",
       "      <td>71.43</td>\n",
       "      <td>6.47</td>\n",
       "      <td>57.13</td>\n",
       "      <td>1.80</td>\n",
       "      <td>39.60</td>\n",
       "      <td>15.70</td>\n",
       "      <td>58.48</td>\n",
       "      <td>6.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Phi-3.5 Vision 4B</td>\n",
       "      <td>49.27</td>\n",
       "      <td>1.90</td>\n",
       "      <td>53.03</td>\n",
       "      <td>3.03</td>\n",
       "      <td>42.90</td>\n",
       "      <td>1.33</td>\n",
       "      <td>31.23</td>\n",
       "      <td>8.43</td>\n",
       "      <td>44.11</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  1a mc  1a oe  1b mc  1b oe  1c mc  1c oe   2 mc  \\\n",
       "0          Gemini1.5 Flash  78.17  16.30  82.07  23.53  71.33   7.33  66.00   \n",
       "1                    GPT4o  88.40  16.60  90.43  35.47  82.23  12.60  63.60   \n",
       "2               GPT4o-mini  75.33   7.30  83.00  17.67  64.83   3.53  52.87   \n",
       "3       Llava1.6 Vicuna 7B  33.63   0.87  43.13   2.83  28.67   0.60  27.77   \n",
       "4      Llava1.6 Vicuna 13B  40.87   1.00  50.30   4.17  38.37   1.60  31.07   \n",
       "5               Molmo-D 7B  50.67   1.00  57.00   2.23  48.67   1.73  36.73   \n",
       "6               Molmo-O 7B  46.03   2.13  43.27   4.37  41.60   2.10  26.83   \n",
       "7               Molmo-E 1B  21.87   0.00  24.53   0.13  20.23   0.00  19.60   \n",
       "8   Llama 3.2 Instruct 11B  57.93  14.37  65.57  19.20  56.27   9.50  46.60   \n",
       "9   Llama 3.2 Instruct 90B  77.33  14.27  83.43  22.30  71.23   9.00  64.70   \n",
       "10             Pixtral 12B  57.57   0.60  72.33   1.83  55.40   0.57  44.73   \n",
       "11    Qwen2 VL Instruct 2B  40.97   3.33  44.40   4.60  47.07   3.43  48.37   \n",
       "12    Qwen2 VL Instruct 7B  63.83   4.07  67.20   8.57  57.00   3.90  56.80   \n",
       "13                Aria 25B  65.77   2.67  71.43   6.47  57.13   1.80  39.60   \n",
       "14       Phi-3.5 Vision 4B  49.27   1.90  53.03   3.03  42.90   1.33  31.23   \n",
       "\n",
       "     2 oe  avg_all_mc  avg_all_oe  \n",
       "0   32.30       74.39       19.86  \n",
       "1   35.53       81.17       25.05  \n",
       "2   26.90       69.01       13.85  \n",
       "3    7.93       33.30        3.06  \n",
       "4    8.63       40.15        3.85  \n",
       "5   11.70       48.27        4.16  \n",
       "6    9.03       39.43        4.41  \n",
       "7    1.27       21.56        0.35  \n",
       "8   27.23       56.59       17.58  \n",
       "9   29.73       74.17       18.82  \n",
       "10  12.83       57.51        3.96  \n",
       "11  12.50       45.20        5.96  \n",
       "12  21.23       61.21        9.44  \n",
       "13  15.70       58.48        6.66  \n",
       "14   8.43       44.11        3.67  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(res)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
